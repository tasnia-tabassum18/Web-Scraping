# -*- coding: utf-8 -*-
"""Web_Scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZYqc-sKQ4nh0nzEaNmYyEEa3WiPiTar6
"""

import requests

res = requests.get('https://realpython.github.io/fake-jobs/')

print(res.text)
print(res.status_code)

import requests

# Make a request to https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/
# Store the result in 'res' variable
res = requests.get(
    'https://realpython.github.io/fake-jobs/')
txt = res.text
status = res.status_code

print(txt, status)

from bs4 import BeautifulSoup

page = requests.get("https://realpython.github.io/fake-jobs/")
soup = BeautifulSoup(page.content, 'html.parser')
title = soup.title.text # gets you the text of the <title>(...)</title>
# Extract title of page
page_title = soup.title.text

# print the result
print(page_title)
# Extract body of page
page_body = soup.body

# Extract head of page
page_head = soup.head

# print the result
print(page_title, page_head)

import requests
from bs4 import BeautifulSoup
import csv
# Make a request
page = requests.get(
    "https://realpython.github.io/fake-jobs/")
soup = BeautifulSoup(page.content, 'html.parser')

# Create jobs as empty list
all_jobs_list = []

# Extract jobs
all_jobs = soup.select('div.is-half')
# print(all_jobs)

for job in all_jobs:
  job_title= job.find('h2').text.strip()
  # print(job_title)
  company = job.select('h3.subtitle')[0].text.strip()
  location = job.select('p.location')[0].text.strip()
  date = job.select('time')[0].text.strip()
 
  all_jobs_list.append({
        "job": job_title,
        "company": company,
        "location": location,
        "date": date,
      
  })
for job in all_jobs_list:
    print(job)

keys = all_jobs_list[0].keys()

with open('jobs.csv', 'w', newline='') as output_file:
    dict_writer = csv.DictWriter(output_file, keys)
    dict_writer.writeheader()
    dict_writer.writerows(all_jobs_list)